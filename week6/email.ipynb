{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* We are going to use email data from program-l mailing list to build edges and nodes for the graph.\n",
    ">* https://www.freelists.org/archive/program-l\n",
    "> * Let's read file using `pd.read_feather` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* feather file is a fast, lightweight, and easy-to-use binary file format for storing data frames. \n",
    ">* Downloading pre-requisite libraries may necessary to read feather file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_feather('sample-feather.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * Let's check the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['thread_id', 'thread_name', 'body', 'account', 'url', 'date',\n",
       "       'longevity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's check datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thread_id                int64\n",
       "thread_name             object\n",
       "body                    object\n",
       "account                 object\n",
       "url                     object\n",
       "date                    object\n",
       "longevity      timedelta64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's check the first few rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>thread_name</th>\n",
       "      <th>body</th>\n",
       "      <th>account</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>longevity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5608</td>\n",
       "      <td>Tool-to-log-all-messages-targeting-a-given-window</td>\n",
       "      <td>[Hello all, Does someone here know of a tool t...</td>\n",
       "      <td>[webmaster, jtwauthier, soronel.haetir]</td>\n",
       "      <td>[https://www.freelists.org/post/program-l/Tool...</td>\n",
       "      <td>[2016-01-19T10:12:01.000000000, 2016-01-19T15:...</td>\n",
       "      <td>0 days 06:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6826</td>\n",
       "      <td>html5js-newby</td>\n",
       "      <td>[HI All, I'm trying to create a demo for aira ...</td>\n",
       "      <td>[blindwiz, taksantong, blindwiz]</td>\n",
       "      <td>[https://www.freelists.org/post/program-l/html...</td>\n",
       "      <td>[2019-02-20T07:34:07.000000000, 2019-02-20T17:...</td>\n",
       "      <td>0 days 13:54:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4209</td>\n",
       "      <td>Searching-in-dataTables-vbnet</td>\n",
       "      <td>[Hi all. A dataTable is the registers of one t...</td>\n",
       "      <td>[pmorales, ofbgmail, pmorales, ofbgmail, pmora...</td>\n",
       "      <td>[https://www.freelists.org/post/program-l/Sear...</td>\n",
       "      <td>[2013-09-02T23:01:35.000000000, 2013-09-03T15:...</td>\n",
       "      <td>5 days 17:13:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2119</td>\n",
       "      <td>Ot-looking-for-an-app</td>\n",
       "      <td>[Hello, I've got an assignment for management ...</td>\n",
       "      <td>[compgeek13, justind, wunderg]</td>\n",
       "      <td>[https://www.freelists.org/post/program-l/Ot-l...</td>\n",
       "      <td>[2008-11-11T00:52:32.000000000, 2008-11-11T13:...</td>\n",
       "      <td>0 days 14:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2906</td>\n",
       "      <td>Learn-Python-The-Hard-Way-Second-Edition</td>\n",
       "      <td>[Hi, For those interested, Learn Python Hard W...</td>\n",
       "      <td>[james.homme, jr]</td>\n",
       "      <td>[https://www.freelists.org/post/program-l/Lear...</td>\n",
       "      <td>[2011-12-05T12:45:48.000000000, 2011-12-05T16:...</td>\n",
       "      <td>0 days 04:05:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   thread_id                                        thread_name  \\\n",
       "0       5608  Tool-to-log-all-messages-targeting-a-given-window   \n",
       "1       6826                                      html5js-newby   \n",
       "2       4209                      Searching-in-dataTables-vbnet   \n",
       "3       2119                              Ot-looking-for-an-app   \n",
       "4       2906           Learn-Python-The-Hard-Way-Second-Edition   \n",
       "\n",
       "                                                body  \\\n",
       "0  [Hello all, Does someone here know of a tool t...   \n",
       "1  [HI All, I'm trying to create a demo for aira ...   \n",
       "2  [Hi all. A dataTable is the registers of one t...   \n",
       "3  [Hello, I've got an assignment for management ...   \n",
       "4  [Hi, For those interested, Learn Python Hard W...   \n",
       "\n",
       "                                             account  \\\n",
       "0            [webmaster, jtwauthier, soronel.haetir]   \n",
       "1                   [blindwiz, taksantong, blindwiz]   \n",
       "2  [pmorales, ofbgmail, pmorales, ofbgmail, pmora...   \n",
       "3                     [compgeek13, justind, wunderg]   \n",
       "4                                  [james.homme, jr]   \n",
       "\n",
       "                                                 url  \\\n",
       "0  [https://www.freelists.org/post/program-l/Tool...   \n",
       "1  [https://www.freelists.org/post/program-l/html...   \n",
       "2  [https://www.freelists.org/post/program-l/Sear...   \n",
       "3  [https://www.freelists.org/post/program-l/Ot-l...   \n",
       "4  [https://www.freelists.org/post/program-l/Lear...   \n",
       "\n",
       "                                                date       longevity  \n",
       "0  [2016-01-19T10:12:01.000000000, 2016-01-19T15:... 0 days 06:12:00  \n",
       "1  [2019-02-20T07:34:07.000000000, 2019-02-20T17:... 0 days 13:54:20  \n",
       "2  [2013-09-02T23:01:35.000000000, 2013-09-03T15:... 5 days 17:13:11  \n",
       "3  [2008-11-11T00:52:32.000000000, 2008-11-11T13:... 0 days 14:42:00  \n",
       "4  [2011-12-05T12:45:48.000000000, 2011-12-05T16:... 0 days 04:05:30  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* In `data` dataframe, we have six columns, each representing as follows:\n",
    "    \n",
    "    * `thread_id` : unique id for each thread\n",
    "    * `thread_name` : the first subject of the email\n",
    "    * `body` : the content of the email \n",
    "    * `account` : the email account of the sender \n",
    "    * `url` : the url of the email\n",
    "    * `date` : the date of the email "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * Think of thread as an email conversation. `thread_id` is the unique id for the email conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's check which thread has the most number of accounts involved in the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39    43\n",
       "63    32\n",
       "81    15\n",
       "73    14\n",
       "33    13\n",
       "      ..\n",
       "57     2\n",
       "58     2\n",
       "59     2\n",
       "66     2\n",
       "85     2\n",
       "Name: account, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['account'].apply(lambda x: len(x)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * The index of 39 has 43 users involved in the conversation.\n",
    "> * Let's see who are the users involved in the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['water.swift', 'rawoolgrove', 'water.swift', 'rawoolgrove',\n",
       "       'shooley2', 'lucasradaelli', 'michael.e.walker3', 'tspivey',\n",
       "       'water.swift', 'michael.e.walker3', 'jamyad7', 'michael.e.walker3',\n",
       "       'jamyad7', 'michael.e.walker3', 'james', 'michael.e.walker3',\n",
       "       'james', 'michael.e.walker3', 'florianbeijers', 'daremc86',\n",
       "       'florianbeijers', 'jacobk', 'jacobk', 'trouble1', 'james',\n",
       "       'michael.e.walker3', 'water.swift', 'water.swift',\n",
       "       'michael.e.walker3', 'michael.e.walker3', 'water.swift',\n",
       "       'michael.e.walker3', 'water.swift', 'michael.e.walker3',\n",
       "       'water.swift', 'michael.e.walker3', 'jacobk', 'dleavens', 'james',\n",
       "       'michael.e.walker3', 'jamyad7', 'compgeek13', 'cmusic789'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[39, 'account']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* We can see some of the users are repeating, meaning they are involved in the conversation multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* We want to see the unique users involved in the conversation.\n",
    ">* To do so, we want to use `nunique()` function to get the number of unique elements in `pd.Series` object.\n",
    "> * So, we have to convert the list into `pd.Series` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39    15\n",
       "63    14\n",
       "33    10\n",
       "6      7\n",
       "73     7\n",
       "      ..\n",
       "30     2\n",
       "29     2\n",
       "24     2\n",
       "99     2\n",
       "47     1\n",
       "Name: account, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['account'].apply(lambda x: pd.Series(x).nunique()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * We can still find the index 39 has the most unique users involved in the conversation.\n",
    "> * But the third most unique users involved in the conversation is different from the most users involved in the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * Let's do text mining on the `body` column to find the most common words used in the conversation.\n",
    "> * To do so, let's import necessary libraries we practiced in the previous classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* We learned the importance of pre-processing before doing text mining.\n",
    "> * Lowercasing, removing punctuation, removing stop words, and tokenization are the most common pre-processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* The body column is a list. We have to join the strings in the list to make it a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1      3\n",
       "2     11\n",
       "3      3\n",
       "4      2\n",
       "      ..\n",
       "95     4\n",
       "96     6\n",
       "97     3\n",
       "98     7\n",
       "99     3\n",
       "Name: body, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['body'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['body-str'] = data['body'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's lowercase the body column first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['body-lower']=data['body-str'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello all, Does someone here know of a tool that could hook to the message loop of an application is able to filter log all messages having a given destination window? In fact, I'm developing a win32 app I would like to know what happens / what messages / notifications are sent when the user press a routine cursor on his braille display to move the cursor a multiline text area. I don't have a braille display myself thus am unable to test alone. Thank you for your answers! If I understand your intent correctly, there are a lot of event intercept logging facilities. Which tools are available depends on the language technologies that power your application. It might be helpful to start by looking the Win32 API docs to see what logging event functions are available. Then you can see if the language or technologies implement those functions. It sounds like you want to hook into the key press events consolidate all of those events into a logger that outputs to a specified dialog or file that can be viewed elsewhere. MS' spy++ can do message logging as described.\n"
     ]
    }
   ],
   "source": [
    "print(data['body-str'].iloc[0]) #before lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello all, does someone here know of a tool that could hook to the message loop of an application is able to filter log all messages having a given destination window? in fact, i'm developing a win32 app i would like to know what happens / what messages / notifications are sent when the user press a routine cursor on his braille display to move the cursor a multiline text area. i don't have a braille display myself thus am unable to test alone. thank you for your answers! if i understand your intent correctly, there are a lot of event intercept logging facilities. which tools are available depends on the language technologies that power your application. it might be helpful to start by looking the win32 api docs to see what logging event functions are available. then you can see if the language or technologies implement those functions. it sounds like you want to hook into the key press events consolidate all of those events into a logger that outputs to a specified dialog or file that can be viewed elsewhere. ms' spy++ can do message logging as described.\n"
     ]
    }
   ],
   "source": [
    "print(data['body-lower'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Okay! lowercasing is done. Now, let's remove the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=stopwords.words('english')\n",
    "#loading stopwords in the variable named stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stopword']=data['body-lower'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop]))\n",
    "#The lambda function takes each row of the 'body-lower' column, splits it into a list of words, \n",
    "#and then joins the words back together into a string, excluding any words that are in the 'stop' list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hi: further to my post yesterday: eclipse has a very good set of example files for the editing or validation of xml files. 1. create a workspace. 2. set your perspective to java. 3. create a new examples project by first opening file / / other menu option. 4. select examples from the list, it should be the last of 22 items. 5. select the xml option. 6. select the editing validation option. a tutorial should appear a new project will be created. i believe five different xml projects are part of the project, each have a step by step tutorial on how to interact with them. 7. programmer / analyst wcag 2. 0 aa assessor / jaws sme enterprise solutions directorate ( besd ). registration, infrastructure support portals ( brisp ) revenue agency | agence du revenu du: h4 - 202 875 road, on k1a 0l5 , keep them coming! this fantastic information is invaluable! i really appreciate your help. i would never have been able to get started the way things were when i first installed eclipse. now i can get going. i am beginning to get more confident xml so i'm about to put your tutorial into practice. i'll let you know how i get on, if you like? hi: yes, let the list know as well. we learn much from other's experiences. are you on the program java list? no, what is that list? it's a list that i created for newby java programmers. it's sort of a tutorial approach along with discussions. i monitor the list on a daily basis but it's rather slow. we / i are mostly focused on eclipse with jaws. it's a way of not cluttering up this list. i posted just today a tutorial for the eclipse xml editor with steps on how to setup use the editor. that's interesting! can you send me the link?\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['body-lower'].iloc[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hi: post yesterday: eclipse good set example files editing validation xml files. 1. create workspace. 2. set perspective java. 3. create new examples project first opening file / / menu option. 4. select examples list, last 22 items. 5. select xml option. 6. select editing validation option. tutorial appear new project created. believe five different xml projects part project, step step tutorial interact them. 7. programmer / analyst wcag 2. 0 aa assessor / jaws sme enterprise solutions directorate ( besd ). registration, infrastructure support portals ( brisp ) revenue agency | agence du revenu du: h4 - 202 875 road, k1a 0l5 , keep coming! fantastic information invaluable! really appreciate help. would never able get started way things first installed eclipse. get going. beginning get confident xml i'm put tutorial practice. i'll let know get on, like? hi: yes, let list know well. learn much other's experiences. program java list? no, list? list created newby java programmers. sort tutorial approach along discussions. monitor list daily basis rather slow. / mostly focused eclipse jaws. way cluttering list. posted today tutorial eclipse xml editor steps setup use editor. that's interesting! send link?\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stopword'].iloc[98]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * This time, let's do tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['token']=data['stopword'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " ':',\n",
       " 'post',\n",
       " 'yesterday',\n",
       " ':',\n",
       " 'eclipse',\n",
       " 'good',\n",
       " 'set',\n",
       " 'example',\n",
       " 'files']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['token'].iloc[98][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Finally let's get rid of the punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['punct_token']=data['token'].apply(lambda x: [word for word in x if word.isalnum()])\n",
    "#if the string is alphanumeric, it is included in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'post',\n",
       " 'yesterday',\n",
       " 'eclipse',\n",
       " 'good',\n",
       " 'set',\n",
       " 'example',\n",
       " 'files',\n",
       " 'editing',\n",
       " 'validation']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['punct_token'].iloc[98][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* We are interested in finding the most common words used in the thread (email conversation) index 39."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('liblouis', 9),\n",
       " ('lou', 8),\n",
       " ('exe', 8),\n",
       " ('0', 4),\n",
       " ('want', 3),\n",
       " ('program', 3),\n",
       " ('python', 3),\n",
       " ('6', 3),\n",
       " ('1', 3),\n",
       " ('thanks', 3)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(data['punct_token'].iloc[30]).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * Let's see which thread has been alive for the longest time.\n",
    "> * Some email lasts for a few days, some for a few months, and some for a few years.\n",
    "> * We can calculate the time difference between the first and the last email of the thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2016-01-19 16:24:01\n",
       "1    2019-02-20 21:28:27\n",
       "2    2013-09-08 16:14:46\n",
       "3    2008-11-11 15:34:32\n",
       "4    2011-12-05 16:51:18\n",
       "             ...        \n",
       "95   2005-02-09 14:19:03\n",
       "96   2012-09-21 18:13:26\n",
       "97   2022-09-09 08:20:39\n",
       "98   2013-11-05 21:50:38\n",
       "99   2012-07-27 08:17:46\n",
       "Name: date, Length: 100, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date'].apply(lambda x: x.max())\n",
    "#max() function will return the latest date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2016-01-19 10:12:01\n",
       "1    2019-02-20 07:34:07\n",
       "2    2013-09-02 23:01:35\n",
       "3    2008-11-11 00:52:32\n",
       "4    2011-12-05 12:45:48\n",
       "             ...        \n",
       "95   2005-02-07 23:54:06\n",
       "96   2012-09-20 08:28:50\n",
       "97   2022-09-08 22:35:03\n",
       "98   2013-11-05 18:59:23\n",
       "99   2012-07-26 08:44:50\n",
       "Name: date, Length: 100, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date'].apply(lambda x: x.min())\n",
    "#min() function will return the earliest date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    1739 days 02:25:49\n",
       "5      10 days 11:32:27\n",
       "75      6 days 19:26:56\n",
       "63      6 days 00:33:38\n",
       "2       5 days 17:13:11\n",
       "            ...        \n",
       "66      0 days 00:40:59\n",
       "85      0 days 00:28:10\n",
       "47      0 days 00:23:22\n",
       "58      0 days 00:10:56\n",
       "84      0 days 00:05:09\n",
       "Name: date, Length: 100, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date'].apply(lambda x: x.max()-x.min()).sort_values(ascending=False) \n",
    "#combining max() and min() function together will reutrn the difference between the latest and earliest date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * Okay, the thread with index 6 has been conversing more than 1000 days!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's see what users have been talking about in the thread with index 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hello, I tried installing the PyCharm IDE, to my dismay, nothing spoke after the installation. Is there an extra step that I have to go through order to get the program to work with NVDA, or is use of PyCharm not available this time, as it is with the InteliJ IDE? Thanks,',\n",
       "       'extra step is to change the IDE. PyCharm is InteliJ based.',\n",
       "       \"Gave it a quick test, while you can make some things start happening using on - screen - OCR, using NVDA 2015. 4, definitely doesn't seem like it will really have much to offer that sense..?\",\n",
       "       'all, I am currently taking an introductory science course college. instructors recommend PyCharm as the coding environment, but I was wondering if it is accessible with NVDA. Even if with some tweaks, I would prefer to use PyCharm along with my sighted peers if possible. If not, please suggest alternative accessible IDEs. I would truly appreciate any assistance. Thanks. - -',\n",
       "       '>>',\n",
       "       'Hi, PyCharm is not fully accessible. So far, the best alternative is VSCode + python extension.',\n",
       "       \"Here is what I've heard of it. IntelliJ Idea is a very similar Java IDE from the same company as PyCharm, so what I say about it probably would be applicable to the other one, since they have the same UI. When I tried it - it wasn't immediately accessible. There are some people on this mailing list who claim that they know how to make it accessible, but despite some requests, they never produced a step - by - step instructions of how to make them accessible. So without any tweaks it is probably safe to say that it's not accessible. company itself ( JetBrains ) is known to have been pretty much ignoring accessibility requests the past. As a formerly sighted user of IDEA, I can confirm that IDEA is probably the best Java IDE out there, because of its superior autocomplete refactoring features among others. same can probably be said about PyCharm, although I had very little experience with it. However given their attitude towards accessibility I ouldn't recommend investing time into their products. As for good alternatives, many people have suggested VSCode, which is getting more more popular both sighted blind communities has very good accessibility. Another alternative to consider is Eclipse - it is fully accessible it has good python support via extension. - - P. S. I'm impressed that you're studying - must be pretty challenging!\",\n",
       "       '>>',\n",
       "       'all, Thanks so much everyone for your suggestions. With the consent of my course instructors, I will be using VSCode for this class. I am facing issues with it which I will post about separate threads. Thanks.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[6, 'body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2015-12-22T10:17:47.000000000', '2015-12-22T10:21:16.000000000',\n",
       "       '2015-12-22T10:37:10.000000000', '2020-09-20T16:59:13.000000000',\n",
       "       '2020-09-20T17:42:55.000000000', '2020-09-20T17:44:12.000000000',\n",
       "       '2020-09-20T20:30:17.000000000', '2020-09-21T08:29:08.000000000',\n",
       "       '2020-09-25T12:43:36.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[6, 'date']\n",
    "#The earlist date of this conversation is 2015-12-22 and the latest date is 2020-09-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's see the most common words used in the thread that has been alive for the longest time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pycharm', 8),\n",
       " ('accessible', 8),\n",
       " ('ide', 5),\n",
       " ('step', 4),\n",
       " ('thanks', 4),\n",
       " ('probably', 4),\n",
       " ('nvda', 3),\n",
       " ('make', 3),\n",
       " ('using', 3),\n",
       " ('much', 3)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(data['punct_token'].iloc[6]).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's jump into the network part of this data.\n",
    ">* Always remember there are three main components of a network: nodes, edges, and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* How do you want to design the graph with the given data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.path_graph(5)\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=nx.complete_graph(5)\n",
    "nx.draw(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * If we think about directionality, the path graph will look like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.path_graph(5, create_using=nx.DiGraph())\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* But given the nature of back-and-forth conversation in the email, there is high likelihood that the graph will be undirected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_directed=nx.complete_graph(5, create_using=nx.DiGraph())\n",
    "nx.draw(C_directed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * Let's think about nodes\n",
    "> * Where can we get the nodes from? It is in the `account` column but data is in the list object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['account']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* How many unique nodes are there in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([item for sublist in data['account'] for item in sublist]).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * Let's build edges between users in the conversation (thread).\n",
    "> * To do so, we will use the `account` column and iterate over the rows to created edges between users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will need a combination of all the accounts in the 'account' column to create the edges of the graph\n",
    "#We will use itertools.combinations to create the combination\n",
    "\n",
    "import itertools\n",
    "edges=[]\n",
    "for idx, val in data['account'].items():\n",
    "    edges.extend(list(itertools.combinations(val, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's get rid of the self-loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_loop = [edge for edge in edges if edge[0] != edge[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_loop[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* We can also get rid of the duplicate edges if we want to design the graph as an unwieghted graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_loop = list(set(edges_loop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_loop[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's see who has the highest degree centrality in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree={}\n",
    "for element in pd.Series([item for sublist in data['account'] for item in sublist]).unique():\n",
    "    count=0\n",
    "    for edge in edges_loop:\n",
    "        if element in edge:\n",
    "            count+=1\n",
    "    degree[element]=count    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * To sort degree based on the value of the degree, we can use `sorted` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_x = sorted(degree.items(), key=lambda k: k[1], reverse=True)\n",
    "sorted_dict = dict(sorted_x)\n",
    "dict(list(sorted_dict.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centrality={}\n",
    "for key, value in sorted_dict.items():\n",
    "    degree_centrality[key]=value/(len(pd.Series([item for sublist in data['account'] for item in sublist]).unique())-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* `jacobk` has the highest degree centrality in the graph.\n",
    ">* Let's compare `jacobk` degree centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centrality['jacobk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* This time, we want to subset the data to only include the conversation that has involved `jacobk`.\n",
    ">* Hint! `isin` function can be useful. Remember `isin()` function is from `pd.Series` object.\n",
    ">* Also, try `.apply()` and `lambda` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's put the result in `jacobkdf` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* We are curious about the most common words that `jacobk` has used in the conversation.\n",
    ">* We have to use `body` column because in `punct-token` we already joined all the strings in the `body` column.\n",
    ">* The strings in `body` column follow the order in the `account` column, meaning the first string in `body` column has been sent by the first user in the `account` column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's find the index (order) of `jacobk` in the `account` column in the `jacobkdf` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's print what `jacobk` sent in the conversation.\n",
    ">* You can use the index (order) found in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Okay, `jacobk` has sent 31 emails in 13 different threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's do text mining:\n",
    ">* (1) Lowercasing\n",
    ">* (2) Tokenization\n",
    ">* (3) Removing stopwords\n",
    ">* (4) Removing punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* (1) Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * (2) Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* (3) Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * (4) Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* If we did all the pre-processing steps correctly, we can find the most common words used by `jacobk` in the conversation.\n",
    ">* Q. What are the most 10 common words used by `jacobk`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's build edges from the `jacobkdf` dataframe.\n",
    ">* To do so, let's iterate over the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's get rid of the self-loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Let's get rid of the duplicate edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* How many edges are there in the final graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
